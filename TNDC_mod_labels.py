import os
import torch
import numpy as np
import json
import sys
from tqdm import tqdm
import random
from collections import defaultdict
import hdbscan
from scipy.spatial.distance import correlation
import argparse
import warnings
warnings.filterwarnings("ignore", category=FutureWarning, message=".*'force_all_finite' was renamed to 'ensure_all_finite'.*")




# -------------------------- å‘½ä»¤è¡Œå‚æ•°è§£æ --------------------------
parser = argparse.ArgumentParser(description="Noise Label Correction with HDBSCAN")
parser.add_argument('--dataset_name', type=str, default='cifar100',
                    choices=['cifar10', 'cifar100', 'tiny_imagenet', 'web-aircraft', 'web-bird', 'web-car'],
                    help='Name of the dataset')
parser.add_argument('--noise_mode', type=str, default='idn',
                    choices=['sym', 'asym', 'idn', 'asym_var'],
                    help='Type of noise: symmetric (sym) or asymmetric (asym)')
parser.add_argument('--noise_ratio', type=float, default=0.8,
                    help='Noise ratio (e.g., 0.2 for 20%)')

args = parser.parse_args()

# ä½¿ç”¨å‘½ä»¤è¡Œå‚æ•°
dataset_name = args.dataset_name
noise_mode = args.noise_mode
noise_ratio = args.noise_ratio



# å…¨å±€å‚æ•°é…ç½®
# sys.path.append('/mnt/zfj/projects/TNDC')
# dataset_name = 'cifar100'  # å¯åˆ‡æ¢ä¸º 'cifar10'/'stanford_cars' ç­‰
feature_dir = f'./saved_features/{dataset_name}_features_no_aug.pth'
root_path = '/mnt/zfj/projects/phd/projects_phd/CWU/saved/saved_features'
os.makedirs(root_path, exist_ok=True)

# -------------------------- 1. æ•°æ®é›†è·¯å¾„ä¸è®¾å¤‡é…ç½® --------------------------
# æ•°æ®é›†è·¯å¾„æ˜ å°„
dataset_path_map = {
    'cifar10': './datasets/cifar-10-batches-py',
    'cifar100': './datasets/cifar-100-python',
    'tiny_imagenet': '/mnt/zfj/dataset/tiny-imagenet-200',
    'web-aircraft': '/home/zhangfeng/zhangfangjiao/datasets/NPN/web-aircraft',
    'web-bird': '/home/zhangfeng/zhangfangjiao/datasets/NPN/web-bird',
    'web-car': '/home/zhangfeng/zhangfangjiao/datasets/NPN/web-car'
}
dataset_path = dataset_path_map.get(dataset_name, '')
if not dataset_path:
    raise ValueError(f"æœªé…ç½® {dataset_name} çš„æ•°æ®é›†è·¯å¾„")

# è®¾å¤‡é…ç½®ï¼ˆä¼˜å…ˆGPUï¼‰
device = torch.device("cuda:1" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}\n")

# -------------------------- 2. æ•°æ®åŠ è½½ï¼ˆå«å™ªå£°æ ‡ç­¾ä¸å¹²å‡€æ ‡ç­¾ï¼‰ --------------------------
if dataset_name in ['cifar10', 'cifar100']:
    from dataloader import dataloader_cifar as dataloader
    # åŠ è½½å¸¦å™ªå£°çš„CIFARæ•°æ®é›†ï¼ˆasymæ¨¡å¼ï¼Œ20%å™ªå£°ç‡ï¼‰
    loader = dataloader.cifar_dataloader(
        dataset_name,
        noise_mode=noise_mode,          # â† ä½¿ç”¨ args.noise_mode
        noise_ratio=noise_ratio,        # â† ä½¿ç”¨ args.noise_ratio
        batch_size=64,
        num_workers=8,
        root_dir=dataset_path,
        model='dino'
    )
    train_loader = loader.run('train')
    test_loader = loader.run('test')

    # æå–å…³é”®æ ‡ç­¾ä¿¡æ¯ï¼ˆå™ªå£°æ ‡ç­¾/å¹²å‡€æ ‡ç­¾/ç±»åˆ«æ•°ï¼‰
    noise_label = torch.tensor(train_loader.dataset.noise_label).to(device)
    clean_label = torch.tensor(train_loader.dataset.clean_label).to(device)
    num_class = 10 if dataset_name == 'cifar10' else 100
    print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼š{dataset_name}ï¼Œæ ·æœ¬æ•°ï¼š{len(train_loader.dataset)}ï¼Œç±»åˆ«æ•°ï¼š{num_class}\n")

elif dataset_name == "tiny_imagenet":
    print("Loading Tiny-ImageNet...")
    import sys
    sys.path.append('/mnt/zfj/projects/phd/projects_phd/DeFT-main')
    from utils.config import _C as cfg
    from dataloader import dataloader_tiny_imagenet as dataloader

    cfg.defrost()
    cfg.merge_from_file('/mnt/zfj/projects/phd/projects_phd/DeFT-main/config/PEFT/tiny_imagenet.yaml')
    train_loader, eval_loader, test_loader = dataloader.build_loader(cfg)

    noise_idx = eval_loader.dataset.noise_idx
    noise_label = torch.tensor(eval_loader.dataset.noise_label).to(device)
    clean_label = torch.tensor(eval_loader.dataset.clean_label).to(device)
    num_class = 200
    print(f"æ•°æ®é›†åŠ è½½å®Œæˆï¼š{dataset_name}ï¼Œæ ·æœ¬æ•°ï¼š{len(train_loader.dataset)}ï¼Œç±»åˆ«æ•°ï¼š{num_class}\n")

else:
    raise NotImplementedError(f"{dataset_name} çš„æ•°æ®åŠ è½½é€»è¾‘æœªå®ç°")

# -------------------------- 3. ç‰¹å¾åŠ è½½ --------------------------
checkpoint = torch.load(feature_dir)
features_tensor = checkpoint['features'].to(device)  # å½¢çŠ¶ï¼š(æ ·æœ¬æ•°, ç‰¹å¾ç»´åº¦)
labels_tensor = checkpoint['labels'].to(device)      # åŸå§‹æ ‡ç­¾ï¼ˆå¤‡ç”¨ï¼‰
# labels_tensor = checkpoint['clean_labels'].to(device)      # åŸå§‹æ ‡ç­¾ï¼ˆå¤‡ç”¨ï¼‰
print(f"ç‰¹å¾åŠ è½½å®Œæˆï¼šç‰¹å¾å½¢çŠ¶ {features_tensor.shape}ï¼Œæ ‡ç­¾å½¢çŠ¶ {labels_tensor.shape}\n")

# -------------------------- 4. åŠŸèƒ½1ï¼šå™ªå£°æ ‡ç­¾ç±»çš„æ­£ç¡®æ ‡ç­¾å æ¯”åˆ†æ --------------------------
def analyze_noise_class_accuracy(clean_labels, noise_labels, num_classes):
    """ç»Ÿè®¡æ¯ä¸ªå™ªå£°æ ‡ç­¾ç±»ä¸­ï¼ŒçœŸå®æ ‡ç­¾ä¸å™ªå£°æ ‡ç­¾ä¸€è‡´çš„æ ·æœ¬å æ¯”"""
    print("===== å¼€å§‹å™ªå£°æ ‡ç­¾ç±»æ­£ç¡®æ ‡ç­¾å æ¯”åˆ†æ =====")
    clean_labels_np = clean_labels.cpu().numpy()
    noise_labels_np = noise_labels.cpu().numpy()
    
    # æŒ‰å™ªå£°æ ‡ç­¾åˆ†ç»„ç»Ÿè®¡
    noise_class_stats = defaultdict(lambda: {'total': 0, 'correct': 0})
    for true_lbl, noisy_lbl in zip(clean_labels_np, noise_labels_np):
        noise_class_stats[noisy_lbl]['total'] += 1
        if true_lbl == noisy_lbl:
            noise_class_stats[noisy_lbl]['correct'] += 1
    
    # è¾“å‡ºæ¯ä¸ªå™ªå£°æ ‡ç­¾ç±»çš„ç»“æœ
    for noisy_class in range(num_classes):
        stats = noise_class_stats[noisy_class]
        total = stats['total']
        if total == 0:
            print(f"å™ªå£°æ ‡ç­¾ç±» {noisy_class}ï¼šæ— æ ·æœ¬")
            continue
        correct_ratio = (stats['correct'] / total) * 100
        print(f"å™ªå£°æ ‡ç­¾ç±» {noisy_class}ï¼šæ€»æ ·æœ¬æ•° {total}ï¼Œæ­£ç¡®æ ‡ç­¾å æ¯” {correct_ratio:.2f}%")
    print("===== å™ªå£°æ ‡ç­¾ç±»åˆ†æå®Œæˆ =====\n")



# -------------------------- 5. åŠŸèƒ½2ï¼šHDBSCANèšç±»åˆ†æï¼ˆå«ç°‡å†…æ ‡ç­¾æ­£ç¡®æ¯”ä¾‹ï¼‰ --------------------------

def hdbscan_cluster_analysis(features, noise_labels, clean_labels, num_classes, K=10, N=3, THRESHOLD=0.6, MIN_REPRESENTATIVE_SAMPLES=1000):
    """
    å¯¹æ¯ä¸ªå™ªå£°æ ‡ç­¾ç±»æ‰§è¡ŒHDBSCANèšç±»ï¼Œæ£€æŸ¥ top-K ç°‡ï¼Œ
    åˆå¹¶æ‰€æœ‰æ»¡è¶³ THRESHOLD çš„ç°‡ï¼Œç›´åˆ°æ€»æ ·æœ¬ â‰¥ MIN_REPRESENTATIVE_SAMPLESã€‚
    """
    print("===== å¼€å§‹HDBSCANèšç±»åˆ†æï¼ˆå¤šç°‡åˆå¹¶æ¨¡å¼ï¼‰ =====")
    noise_labels_np = noise_labels.cpu().numpy()
    clean_labels_np = clean_labels.cpu().numpy()
    features_np = features.cpu().numpy()
    
    label_to_indices = defaultdict(list)
    for idx, lbl in enumerate(noise_labels_np):
        label_to_indices[lbl].append(idx)
    
    cluster_analysis_results = {}
    total_checked_samples_per_class = {}

    for noisy_label in tqdm(label_to_indices.keys(), desc="Processing classes for HDBSCAN"):
        sample_indices = label_to_indices[noisy_label]
        if len(sample_indices) < K * N:
            print(f"è·³è¿‡ç±» {noisy_label}ï¼ˆæ ·æœ¬æ•°ä¸è¶³ï¼š{len(sample_indices)} < {K*N}ï¼‰")
            total_checked_samples_per_class[noisy_label] = 0
            continue
        
        class_features = features_np[sample_indices]
        clusterer = hdbscan.HDBSCAN(
            min_cluster_size=5,
            metric='correlation',
            cluster_selection_method='eom'
        )
        cluster_labels = clusterer.fit_predict(class_features)
        
        cluster_counts = defaultdict(int)
        for lbl in cluster_labels:
            if lbl != -1:
                cluster_counts[lbl] += 1
        
        if not cluster_counts:
            print(f"ç±» {noisy_label} æ— æœ‰æ•ˆç°‡")
            total_checked_samples_per_class[noisy_label] = 0
            continue
        
        sorted_clusters = sorted(cluster_counts.items(), key=lambda x: x[1], reverse=True)[:K]
        top_cluster_ids = [cid for cid, _ in sorted_clusters]
        
        cluster_details = []
        checked_samples_count = 0
        qualified_clusters = []  # å­˜å‚¨åˆæ ¼ç°‡çš„å…¨å±€ç´¢å¼•
        total_qualified_samples = 0

        for cluster_id in top_cluster_ids:
            cluster_mask = (cluster_labels == cluster_id)
            cluster_in_class_indices = np.where(cluster_mask)[0]
            cluster_global_indices = [sample_indices[i] for i in cluster_in_class_indices]
            
            sample_count = min(N, len(cluster_global_indices))
            if sample_count == 0:
                continue
            sampled_global_indices = np.random.choice(cluster_global_indices, size=sample_count, replace=False)
            sampled_true_labels = [clean_labels_np[idx] for idx in sampled_global_indices]
            sampled_correct = sum(1 for tl in sampled_true_labels if tl == noisy_label)
            sampled_correct_ratio = sampled_correct / sample_count
            
            checked_samples_count += sample_count

            cluster_details.append({
                "cluster_id": cluster_id,
                "total_samples": len(cluster_global_indices),
                "sampled_count": sample_count,
                "sampled_correct_ratio": sampled_correct_ratio,
                "qualified": sampled_correct_ratio >= THRESHOLD
            })

            # å¦‚æœåˆæ ¼ï¼ŒåŠ å…¥å€™é€‰
            if sampled_correct_ratio >= THRESHOLD:
                qualified_clusters.append(cluster_global_indices)
                total_qualified_samples += len(cluster_global_indices)
                # æå‰ç»ˆæ­¢æ¡ä»¶ï¼šè¶³å¤Ÿå¤šçš„ä»£è¡¨æ ·æœ¬
                if total_qualified_samples >= MIN_REPRESENTATIVE_SAMPLES:
                    break

        found_representative = total_qualified_samples > 0

        cluster_analysis_results[noisy_label] = {
            "total_samples_in_class": len(sample_indices),
            "cluster_details": cluster_details,
            "found_representative": found_representative,
            "total_checked_samples": checked_samples_count,
            "total_qualified_samples": total_qualified_samples,
            "num_qualified_clusters": len(qualified_clusters)
        }
        total_checked_samples_per_class[noisy_label] = checked_samples_count
    
    # è¾“å‡ºç»“æœ
    for noisy_label, result in cluster_analysis_results.items():
        print(f"\nç±»ï¼ˆå™ªå£°æ ‡ç­¾ï¼‰{noisy_label}ï¼šæ€»æ ·æœ¬æ•° {result['total_samples_in_class']}")
        print(f"  âœ… æ‰¾åˆ°åˆæ ¼ç°‡: {'æ˜¯' if result['found_representative'] else 'å¦'}")
        print(f"  ğŸ“¦ åˆæ ¼ç°‡æ€»æ ·æœ¬æ•°: {result['total_qualified_samples']}ï¼ˆæ¥è‡ª {result['num_qualified_clusters']} ä¸ªç°‡ï¼‰")
        print(f"  ğŸ” æ€»å…±æ£€æŸ¥æ ·æœ¬æ•°: {result['total_checked_samples']}")
        for i, cluster in enumerate(result['cluster_details'], 1):
            mark = "âœ…" if cluster['qualified'] else "âŒ"
            print(f"    {mark} ç°‡ {i}ï¼ˆID: {cluster['cluster_id']}ï¼‰ï¼šæ€»æ ·æœ¬ {cluster['total_samples']}ï¼ŒæŠ½æ · {cluster['sampled_count']} ä¸ªï¼Œæ­£ç¡®æ¯”ä¾‹ {cluster['sampled_correct_ratio']:.4f}")
    
    print("\n===== å„ç±»æ£€æŸ¥æ ·æœ¬é‡æ±‡æ€» =====")
    total_overall_checked = sum(total_checked_samples_per_class.values())
    print(f"æ€»è®¡æ£€æŸ¥æ ·æœ¬æ•°: {total_overall_checked}")
    for lbl in sorted(total_checked_samples_per_class.keys()):
        print(f"  ç±» {lbl}: {total_checked_samples_per_class[lbl]} ä¸ªæ ·æœ¬")
    print("===== HDBSCANèšç±»åˆ†æå®Œæˆ =====\n")
    
    return cluster_analysis_results, total_checked_samples_per_class

# -------------------------- 6. åŠŸèƒ½3ï¼šåŸºäºè´¨å¿ƒçš„æ ‡ç­¾é‡åˆ†é…ä¸å‡†ç¡®ç‡ç»Ÿè®¡ï¼ˆæ–°å¢æ ‡ç­¾ä¿®æ­£åæ ·æœ¬æ•°ï¼‰ --------------------------
### å–æ¯ç±»å‰top_ratio

# def reassign_labels_by_centroid(features, noise_labels, clean_labels, K=10, N=10, THRESHOLD=0.6, top_ratio=0.5, MIN_REPRESENTATIVE_SAMPLES=1000):
#     """
#     åˆå¹¶å¤šä¸ªæ»¡è¶³æ¡ä»¶çš„ç°‡ä½œä¸ºä»£è¡¨æ ·æœ¬ï¼Œç›´åˆ°æ€»æ ·æœ¬ â‰¥ MIN_REPRESENTATIVE_SAMPLESã€‚
#     """
#     print("===== å¼€å§‹åŸºäºè´¨å¿ƒçš„æ ‡ç­¾é‡åˆ†é…ï¼ˆå¤šç°‡åˆå¹¶ + é«˜ç½®ä¿¡åº¦ä¿®æ­£ï¼‰ =====")
#     noise_labels_np = noise_labels.cpu().numpy()
#     clean_labels_np = clean_labels.cpu().numpy()
#     features_np = features.cpu().numpy()
#     total_samples = features_np.shape[0]

#     new_labels_np = noise_labels_np.copy()
#     label_to_indices = defaultdict(list)
#     for idx, lbl in enumerate(noise_labels_np):
#         label_to_indices[lbl].append(idx)

#     class_centroids = {}
#     class_representative_count = {}

#     for noisy_label in tqdm(label_to_indices.keys(), desc="Finding representative clusters (multi-cluster)"):
#         sample_indices = label_to_indices[noisy_label]
#         if len(sample_indices) < K * N:
#             print(f"è·³è¿‡ç±» {noisy_label}ï¼ˆæ ·æœ¬æ•°ä¸è¶³ï¼š{len(sample_indices)}ï¼‰")
#             continue

#         class_features = features_np[sample_indices]
#         clusterer = hdbscan.HDBSCAN(min_cluster_size=5, metric='correlation', cluster_selection_method='eom')
#         cluster_labels = clusterer.fit_predict(class_features)

#         cluster_counts = defaultdict(int)
#         for lbl in cluster_labels:
#             if lbl != -1:
#                 cluster_counts[lbl] += 1

#         if not cluster_counts:
#             centroid = np.mean(class_features, axis=0)
#             class_centroids[noisy_label] = centroid
#             class_representative_count[noisy_label] = len(sample_indices)
#             continue

#         sorted_clusters = sorted(cluster_counts.items(), key=lambda x: x[1], reverse=True)[:K]
#         top_cluster_ids = [cid for cid, _ in sorted_clusters]

#         qualified_global_indices = []
#         total_qualified = 0

#         for cluster_id in top_cluster_ids:
#             cluster_mask = (cluster_labels == cluster_id)
#             cluster_in_class_indices = np.where(cluster_mask)[0]
#             cluster_global_indices = [sample_indices[i] for i in cluster_in_class_indices]
#             rep_count = len(cluster_global_indices)

#             sample_count = min(N, rep_count)
#             if sample_count == 0:
#                 continue
#             sampled_indices = np.random.choice(cluster_global_indices, size=sample_count, replace=False)
#             sampled_true_labels = [clean_labels_np[idx] for idx in sampled_indices]
#             correct_ratio = sum(1 for tl in sampled_true_labels if tl == noisy_label) / sample_count

#             if correct_ratio >= THRESHOLD:
#                 qualified_global_indices.extend(cluster_global_indices)
#                 total_qualified += rep_count
#                 if total_qualified >= MIN_REPRESENTATIVE_SAMPLES:
#                     break  # è¾¾åˆ°ç›®æ ‡ï¼Œæå‰é€€å‡º

#         if qualified_global_indices:
#             # ä½¿ç”¨æ‰€æœ‰åˆæ ¼ç°‡çš„æ ·æœ¬è®¡ç®—è´¨å¿ƒ
#             centroid = np.mean(features_np[qualified_global_indices], axis=0)
#             class_centroids[noisy_label] = centroid
#             class_representative_count[noisy_label] = len(qualified_global_indices)
#         else:
#             # æ— åˆæ ¼ç°‡ï¼Œå›é€€åˆ°å…¨ç±»å‡å€¼
#             centroid = np.mean(class_features, axis=0)
#             class_centroids[noisy_label] = centroid
#             class_representative_count[noisy_label] = len(sample_indices)

#     if not class_centroids:
#         raise ValueError("æ— ä»»ä½•ç±»æ‰¾åˆ°ä»£è¡¨ç°‡ï¼Œæ— æ³•è¿›è¡Œæ ‡ç­¾é‡åˆ†é…")

#     all_classes = list(class_centroids.keys())
#     print(f"\næ‰¾åˆ° {len(all_classes)} ä¸ªç±»çš„ä»£è¡¨ç°‡ï¼ˆå¯èƒ½ç”±å¤šç°‡åˆå¹¶ï¼‰ï¼Œå¼€å§‹è®¡ç®—ç½®ä¿¡åº¦...")

#     # åç»­é€»è¾‘ä¸å˜ï¼šè®¡ç®—è·ç¦»ã€é‡åˆ†é…ç­‰
#     sample_distances = []
#     for i in range(total_samples):
#         feat = features_np[i]
#         min_dist = float('inf')
#         best_class = -1
#         for cls in all_classes:
#             dist = correlation(feat, class_centroids[cls])
#             if dist < min_dist:
#                 min_dist = dist
#                 best_class = cls
#         sample_distances.append((i, best_class, min_dist))

#     pred_class_to_samples = defaultdict(list)
#     for idx, pred_cls, dist in sample_distances:
#         pred_class_to_samples[pred_cls].append((idx, dist))

#     for pred_cls, samples in pred_class_to_samples.items():
#         if not samples:
#             continue
#         samples_sorted = sorted(samples, key=lambda x: x[1])
#         n_keep = max(1, int(len(samples_sorted) * top_ratio))
#         high_conf_samples = samples_sorted[:n_keep]
#         for idx, _ in high_conf_samples:
#             new_labels_np[idx] = pred_cls

#     # ç»Ÿè®¡æŒ‡æ ‡ï¼ˆç•¥ï¼Œä¸åŸé€»è¾‘ä¸€è‡´ï¼‰
#     overall_correct = sum(1 for i in range(total_samples) if new_labels_np[i] == clean_labels_np[i])
#     overall_accuracy = overall_correct / total_samples

#     corrected_class_sample_count = defaultdict(int)
#     for lbl in new_labels_np:
#         corrected_class_sample_count[lbl] += 1

#     class_accuracies = defaultdict(lambda: {
#         'correct': 0, 'total': 0, 'accuracy': 0.0,
#         'representative_sample_count': 0,
#         'corrected_sample_count': 0
#     })

#     for i in range(total_samples):
#         true_lbl = clean_labels_np[i]
#         pred_lbl = new_labels_np[i]
#         class_accuracies[true_lbl]['total'] += 1
#         if true_lbl == pred_lbl:
#             class_accuracies[true_lbl]['correct'] += 1
#         if true_lbl in class_representative_count:
#             class_accuracies[true_lbl]['representative_sample_count'] = class_representative_count[true_lbl]
#         class_accuracies[true_lbl]['corrected_sample_count'] = corrected_class_sample_count.get(true_lbl, 0)

#     for class_label in class_accuracies:
#         total = class_accuracies[class_label]['total']
#         if total > 0:
#             class_accuracies[class_label]['accuracy'] = class_accuracies[class_label]['correct'] / total

#     print(f"\n=== å¤šç°‡åˆå¹¶ + é«˜ç½®ä¿¡åº¦ä¿®æ­£ç»Ÿè®¡ï¼ˆtop {int(top_ratio*100)}%ï¼‰===")
#     print(f"æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f}")
#     print(f"æ€»æ ·æœ¬æ•°: {total_samples}")

#     print("\næ¯ä¸ªç±»çš„è¯¦ç»†ç»Ÿè®¡:")
#     for class_label in sorted(class_accuracies.keys()):
#         acc = class_accuracies[class_label]['accuracy']
#         correct = class_accuracies[class_label]['correct']
#         total = class_accuracies[class_label]['total']
#         rep_count = class_accuracies[class_label]['representative_sample_count']
#         corrected_count = class_accuracies[class_label]['corrected_sample_count']
#         rep_count_str = str(rep_count) if rep_count > 0 else "æ— "
#         print(f"ç±» {class_label}: å‡†ç¡®ç‡ {acc:.4f} ({correct}/{total})ï¼Œä»£è¡¨æ ·æœ¬æ•° {rep_count_str}ï¼Œä¿®æ­£åæ ·æœ¬æ•° {corrected_count}")

#     results = {
#         'overall_accuracy': overall_accuracy,
#         'total_samples': total_samples,
#         'class_accuracies': dict(class_accuracies),
#         'class_centroids': {k: v.tolist() for k, v in class_centroids.items()},
#         'class_representative_counts': class_representative_count,
#         'corrected_class_sample_counts': corrected_class_sample_count
#     }

#     print("===== æ ‡ç­¾é‡åˆ†é…ï¼ˆå¤šç°‡åˆå¹¶ï¼‰å®Œæˆ =====\n")
#     return results, new_labels_np, noise_labels_np



def reassign_labels_by_centroid(features, noise_labels, clean_labels, K=10, N=10, THRESHOLD=0.6, top_ratio=0.5, MIN_REPRESENTATIVE_SAMPLES=1000):
    print("===== å¼€å§‹åŸºäºè´¨å¿ƒçš„æ ‡ç­¾é‡åˆ†é…ï¼ˆå¤šç°‡åˆå¹¶ + é«˜ç½®ä¿¡åº¦ä¿®æ­£ï¼‰ =====")
    noise_labels_np = noise_labels.cpu().numpy()
    clean_labels_np = clean_labels.cpu().numpy()
    features_np = features.cpu().numpy()
    total_samples = features_np.shape[0]

    new_labels_np = noise_labels_np.copy()
    label_to_indices = defaultdict(list)
    for idx, lbl in enumerate(noise_labels_np):
        label_to_indices[lbl].append(idx)

    class_centroids = {}
    class_representative_count = {}

    for noisy_label in tqdm(label_to_indices.keys(), desc="Finding representative clusters (multi-cluster)"):
        sample_indices = label_to_indices[noisy_label]
        if len(sample_indices) < K * N:
            print(f"è·³è¿‡ç±» {noisy_label}ï¼ˆæ ·æœ¬æ•°ä¸è¶³ï¼š{len(sample_indices)}ï¼‰")
            continue

        class_features = features_np[sample_indices]
        clusterer = hdbscan.HDBSCAN(min_cluster_size=5, metric='correlation', cluster_selection_method='eom')
        cluster_labels = clusterer.fit_predict(class_features)

        cluster_counts = defaultdict(int)
        for lbl in cluster_labels:
            if lbl != -1:
                cluster_counts[lbl] += 1

        if not cluster_counts:
            centroid = np.mean(class_features, axis=0)
            class_centroids[noisy_label] = centroid
            class_representative_count[noisy_label] = len(sample_indices)
            continue

        sorted_clusters = sorted(cluster_counts.items(), key=lambda x: x[1], reverse=True)[:K]
        top_cluster_ids = [cid for cid, _ in sorted_clusters]

        qualified_global_indices = []
        for cluster_id in top_cluster_ids:
            cluster_mask = (cluster_labels == cluster_id)
            cluster_in_class_indices = np.where(cluster_mask)[0]
            cluster_global_indices = [sample_indices[i] for i in cluster_in_class_indices]
            rep_count = len(cluster_global_indices)

            sample_count = min(N, rep_count)
            if sample_count == 0:
                continue
            sampled_indices = np.random.choice(cluster_global_indices, size=sample_count, replace=False)
            sampled_true_labels = [clean_labels_np[idx] for idx in sampled_indices]
            correct_ratio = sum(1 for tl in sampled_true_labels if tl == noisy_label) / sample_count

            if correct_ratio >= THRESHOLD:
                qualified_global_indices.extend(cluster_global_indices)

        # >>>>>>>>>> æ–°å¢ï¼šé™åˆ¶ä»£è¡¨æ ·æœ¬æœ€å¤šä¸º MIN_REPRESENTATIVE_SAMPLES <<<<<<<<<<
        if len(qualified_global_indices) > MIN_REPRESENTATIVE_SAMPLES:
            qualified_global_indices = np.random.choice(
                qualified_global_indices, size=MIN_REPRESENTATIVE_SAMPLES, replace=False
            ).tolist()

        if qualified_global_indices:
            centroid = np.mean(features_np[qualified_global_indices], axis=0)
            class_centroids[noisy_label] = centroid
            class_representative_count[noisy_label] = len(qualified_global_indices)
        else:
            centroid = np.mean(class_features, axis=0)
            class_centroids[noisy_label] = centroid
            class_representative_count[noisy_label] = len(sample_indices)

    # ... åç»­é€»è¾‘ä¿æŒä¸å˜ ...
    if not class_centroids:
        raise ValueError("æ— ä»»ä½•ç±»æ‰¾åˆ°ä»£è¡¨ç°‡ï¼Œæ— æ³•è¿›è¡Œæ ‡ç­¾é‡åˆ†é…")

    all_classes = list(class_centroids.keys())
    print(f"\næ‰¾åˆ° {len(all_classes)} ä¸ªç±»çš„ä»£è¡¨ç°‡ï¼ˆå¯èƒ½ç”±å¤šç°‡åˆå¹¶ï¼‰ï¼Œå¼€å§‹è®¡ç®—ç½®ä¿¡åº¦...")

    # åç»­é€»è¾‘ä¸å˜ï¼šè®¡ç®—è·ç¦»ã€é‡åˆ†é…ç­‰
    sample_distances = []
    for i in range(total_samples):
        feat = features_np[i]
        min_dist = float('inf')
        best_class = -1
        for cls in all_classes:
            dist = correlation(feat, class_centroids[cls])
            if dist < min_dist:
                min_dist = dist
                best_class = cls
        sample_distances.append((i, best_class, min_dist))

    pred_class_to_samples = defaultdict(list)
    for idx, pred_cls, dist in sample_distances:
        pred_class_to_samples[pred_cls].append((idx, dist))

    for pred_cls, samples in pred_class_to_samples.items():
        if not samples:
            continue
        samples_sorted = sorted(samples, key=lambda x: x[1])
        n_keep = max(1, int(len(samples_sorted) * top_ratio))
        high_conf_samples = samples_sorted[:n_keep]
        for idx, _ in high_conf_samples:
            new_labels_np[idx] = pred_cls

    # ç»Ÿè®¡æŒ‡æ ‡ï¼ˆç•¥ï¼Œä¸åŸé€»è¾‘ä¸€è‡´ï¼‰
    overall_correct = sum(1 for i in range(total_samples) if new_labels_np[i] == clean_labels_np[i])
    overall_accuracy = overall_correct / total_samples

    corrected_class_sample_count = defaultdict(int)
    for lbl in new_labels_np:
        corrected_class_sample_count[lbl] += 1

    class_accuracies = defaultdict(lambda: {
        'correct': 0, 'total': 0, 'accuracy': 0.0,
        'representative_sample_count': 0,
        'corrected_sample_count': 0
    })

    for i in range(total_samples):
        true_lbl = clean_labels_np[i]
        pred_lbl = new_labels_np[i]
        class_accuracies[true_lbl]['total'] += 1
        if true_lbl == pred_lbl:
            class_accuracies[true_lbl]['correct'] += 1
        if true_lbl in class_representative_count:
            class_accuracies[true_lbl]['representative_sample_count'] = class_representative_count[true_lbl]
        class_accuracies[true_lbl]['corrected_sample_count'] = corrected_class_sample_count.get(true_lbl, 0)

    for class_label in class_accuracies:
        total = class_accuracies[class_label]['total']
        if total > 0:
            class_accuracies[class_label]['accuracy'] = class_accuracies[class_label]['correct'] / total

    print(f"\n=== å¤šç°‡åˆå¹¶ + é«˜ç½®ä¿¡åº¦ä¿®æ­£ç»Ÿè®¡ï¼ˆtop {int(top_ratio*100)}%ï¼‰===")
    print(f"æ•´ä½“å‡†ç¡®ç‡: {overall_accuracy:.4f}")
    print(f"æ€»æ ·æœ¬æ•°: {total_samples}")

    print("\næ¯ä¸ªç±»çš„è¯¦ç»†ç»Ÿè®¡:")
    for class_label in sorted(class_accuracies.keys()):
        acc = class_accuracies[class_label]['accuracy']
        correct = class_accuracies[class_label]['correct']
        total = class_accuracies[class_label]['total']
        rep_count = class_accuracies[class_label]['representative_sample_count']
        corrected_count = class_accuracies[class_label]['corrected_sample_count']
        rep_count_str = str(rep_count) if rep_count > 0 else "æ— "
        print(f"ç±» {class_label}: å‡†ç¡®ç‡ {acc:.4f} ({correct}/{total})ï¼Œä»£è¡¨æ ·æœ¬æ•° {rep_count_str}ï¼Œä¿®æ­£åæ ·æœ¬æ•° {corrected_count}")

    results = {
        'overall_accuracy': overall_accuracy,
        'total_samples': total_samples,
        'class_accuracies': dict(class_accuracies),
        'class_centroids': {k: v.tolist() for k, v in class_centroids.items()},
        'class_representative_counts': class_representative_count,
        'corrected_class_sample_counts': corrected_class_sample_count
    }

    print("===== æ ‡ç­¾é‡åˆ†é…ï¼ˆå¤šç°‡åˆå¹¶ï¼‰å®Œæˆ =====\n")
    return results, new_labels_np, noise_labels_np


# -------------------------- 7. åŠŸèƒ½4ï¼šç»Ÿè®¡ä¿®æ­£åæ¯ä¸ªç±»ä¸­çœŸå®ç±»åˆ«çš„åˆ†å¸ƒï¼ˆå‰ä¸‰å æ¯”ï¼‰ --------------------------
def analyze_corrected_class_composition(new_labels, clean_labels, num_classes):
    """
    åˆ†ææ ‡ç­¾ä¿®æ­£åï¼Œæ¯ä¸ªæ–°ç±»ä¸­åŒ…å«å“ªäº›çœŸå®ç±»åˆ«çš„æ ·æœ¬ï¼Œè¾“å‡ºå æ¯”å‰ä¸‰çš„çœŸå®ç±»åˆ«ï¼Œ
    å¹¶ç»Ÿè®¡ Noise-dominant class çš„æ•°é‡ï¼ˆå³ï¼šä¿®æ­£åç±»ä¸­å æ¯”æœ€é«˜çš„çœŸå®ç±» â‰  ä¿®æ­£åç±»æ ‡ç­¾ï¼‰ã€‚
    """
    print("===== å¼€å§‹åˆ†ææ ‡ç­¾ä¿®æ­£åå„ç±»çš„ç»„æˆï¼ˆçœŸå®ç±»åˆ«åˆ†å¸ƒï¼‰ =====")
    
    # æ„å»ºï¼šæ¯ä¸ªä¿®æ­£åçš„ç±» -> å…¶åŒ…å«çš„æ‰€æœ‰çœŸå®æ ‡ç­¾
    corrected_class_to_true = defaultdict(list)
    for pred_lbl, true_lbl in zip(new_labels, clean_labels):
        corrected_class_to_true[pred_lbl].append(true_lbl)
    
    noise_dominant_count = 0  # è®¡æ•°å™¨

    # éå†æ¯ä¸ªä¿®æ­£åçš„ç±»
    for corrected_label in sorted(corrected_class_to_true.keys()):
        true_labels_in_class = corrected_class_to_true[corrected_label]
        total = len(true_labels_in_class)
        
        # ç»Ÿè®¡å„çœŸå®ç±»åˆ«çš„æ•°é‡
        true_label_counter = defaultdict(int)
        for tl in true_labels_in_class:
            true_label_counter[tl] += 1
        
        # æŒ‰æ•°é‡æ’åºï¼Œå–ç¬¬ä¸€ï¼ˆä¸»å¯¼çœŸå®ç±»ï¼‰
        sorted_true_labels = sorted(true_label_counter.items(), key=lambda x: x[1], reverse=True)
        top1_true_label, top1_count = sorted_true_labels[0]
        top1_ratio = top1_count / total

        # åˆ¤æ–­æ˜¯å¦ä¸º Noise-dominant class
        if top1_true_label != corrected_label:
            noise_dominant_count += 1
            is_noise_dominant = "ğŸ”´ Noise-dominant"
        else:
            is_noise_dominant = "ğŸŸ¢ Clean-dominant"

        # è¾“å‡ºå‰ä¸‰
        top3 = sorted_true_labels[:3]
        print(f"\nä¿®æ­£åç±» {corrected_label}ï¼ˆå…± {total} ä¸ªæ ·æœ¬ï¼‰{is_noise_dominant}")
        for i, (true_lbl, count) in enumerate(top3):
            ratio = count / total
            print(f"  ç¬¬{i+1}å¤§æˆåˆ†: çœŸå®ç±» {true_lbl}, æ•°é‡ {count}, å æ¯” {ratio:.3f} ({ratio*100:.1f}%)")
        
        # å…¶ä»–ç±»æç¤º
        if len(sorted_true_labels) > 3:
            others_count = sum(item[1] for item in sorted_true_labels[3:])
            others_ratio = others_count / total
            print(f"  å…¶ä»– {len(sorted_true_labels) - 3} ä¸ªç±»åˆè®¡: {others_count} æ ·æœ¬, å æ¯” {others_ratio:.3f} ({others_ratio*100:.1f}%)")
    
    print(f"\nğŸ“Š æ€»ç»“ï¼šå…±æœ‰ {noise_dominant_count} ä¸ª Noise-dominant classï¼ˆä¸»å¯¼çœŸå®ç±» â‰  ä¿®æ­£åç±»æ ‡ç­¾ï¼‰")
    print("===== ä¿®æ­£åç±»ç»„æˆåˆ†æå®Œæˆ =====\n")


# -------------------------- æ–°å¢åŠŸèƒ½5ï¼šæŒ‰ç½®ä¿¡åº¦åŒºé—´ç»Ÿè®¡ä¿®æ­£å‰åå‡†ç¡®ç‡ --------------------------
def analyze_accuracy_by_confidence_intervals(
    features, 
    noise_labels, 
    clean_labels, 
    new_labels, 
    class_centroids,
    num_classes
):
    """
    å°†æ‰€æœ‰æ ·æœ¬æŒ‰åˆ°é¢„æµ‹ç±»è´¨å¿ƒçš„è·ç¦»ï¼ˆç½®ä¿¡åº¦ï¼‰æ’åºï¼Œåˆ’åˆ†æˆ10ä¸ªç­‰æ¯”ä¾‹åŒºé—´ï¼Œ
    ç»Ÿè®¡æ¯ä¸ªåŒºé—´å†…ï¼š
        - ä¿®æ­£å‰ï¼ˆnoise_labelsï¼‰çš„å‡†ç¡®ç‡
        - ä¿®æ­£åï¼ˆnew_labelsï¼‰çš„å‡†ç¡®ç‡
    
    å¹¶é¢å¤–ç»Ÿè®¡ï¼šå‰10%ã€20%ã€...ã€100% ç´¯è®¡æ ·æœ¬çš„ä¿®æ­£åæ•´ä½“å‡†ç¡®ç‡ã€‚
    """
    print("===== å¼€å§‹æŒ‰ç½®ä¿¡åº¦åŒºé—´åˆ†æä¿®æ­£å‰åå‡†ç¡®ç‡ =====")
    
    features_np = features.cpu().numpy()
    noise_labels_np = noise_labels.cpu().numpy()
    clean_labels_np = clean_labels.cpu().numpy()
    new_labels_np = np.array(new_labels)
    
    all_classes = list(class_centroids.keys())
    sample_distances = []  # [(index, distance), ...]

    for i in range(len(features_np)):
        feat = features_np[i]
        min_dist = float('inf')
        for cls in all_classes:
            dist = correlation(feat, class_centroids[cls])
            if dist < min_dist:
                min_dist = dist
        sample_distances.append((i, min_dist))
    
    # æŒ‰è·ç¦»å‡åºæ’åºï¼ˆé«˜ç½®ä¿¡åº¦åœ¨å‰ï¼‰
    sample_distances.sort(key=lambda x: x[1])
    sorted_indices = [idx for idx, _ in sample_distances]
    
    total_samples = len(sorted_indices)
    interval_size = total_samples // 10
    results_per_interval = []

    print(f"æ€»æ ·æœ¬æ•°: {total_samples}ï¼Œæ¯åŒºé—´çº¦ {interval_size} æ ·æœ¬")
    
    for i in range(10):
        start = i * interval_size
        end = start + interval_size if i < 9 else total_samples
        interval_indices = sorted_indices[start:end]
        
        if len(interval_indices) == 0:
            continue
            
        clean_sub = clean_labels_np[interval_indices]
        noise_sub = noise_labels_np[interval_indices]
        new_sub = new_labels_np[interval_indices]
        
        acc_before = np.mean(clean_sub == noise_sub)
        acc_after = np.mean(clean_sub == new_sub)
        
        results_per_interval.append({
            'interval': f"{i*10}%â€“{(i+1)*10}%",
            'sample_count': len(interval_indices),
            'acc_before': acc_before,
            'acc_after': acc_after
        })
        
        print(f"åŒºé—´ {i+1:2d} ({i*10:2d}â€“{(i+1)*10:2d}%): "
              f"æ ·æœ¬æ•°={len(interval_indices):4d}, "
              f"ä¿®æ­£å‰å‡†ç¡®ç‡={acc_before:.4f}, "
              f"ä¿®æ­£åå‡†ç¡®ç‡={acc_after:.4f}")
    
    # ==================== æ–°å¢ï¼šç´¯è®¡å‰ N% çš„æ•´ä½“å‡†ç¡®ç‡ ====================
    print("\n===== ç´¯è®¡å‰ N% é«˜ç½®ä¿¡åº¦æ ·æœ¬çš„ä¿®æ­£åæ•´ä½“å‡†ç¡®ç‡ =====")
    cumulative_accuracies = {}
    for p in range(10, 101, 10):
        n_samples = int(total_samples * p / 100)
        if n_samples == 0:
            acc = 0.0
        else:
            top_indices = sorted_indices[:n_samples]
            acc = np.mean(clean_labels_np[top_indices] == new_labels_np[top_indices])
        cumulative_accuracies[f"top_{p}pct"] = float(acc)
        print(f"å‰ {p:3d}% ({n_samples:6d} æ ·æœ¬): ä¿®æ­£åå‡†ç¡®ç‡ = {acc:.4f}")
    
    print("===== ç½®ä¿¡åº¦åŒºé—´ä¸ç´¯è®¡å‡†ç¡®ç‡åˆ†æå®Œæˆ =====\n")
    
    return {
        'interval_results': results_per_interval,
        'cumulative_accuracies': cumulative_accuracies
    }




# æ‰§è¡ŒåŠŸèƒ½1
analyze_noise_class_accuracy(clean_labels=clean_label, noise_labels=noise_label, num_classes=num_class)

# # æ‰§è¡ŒåŠŸèƒ½2ï¼ˆK=10ä¸ªæœ€å¤§ç°‡ï¼ŒN=10ä¸ªæŠ½æ ·æ ·æœ¬ï¼‰
hdbscan_results = hdbscan_cluster_analysis(
    features=features_tensor,
    noise_labels=noise_label,
    clean_labels=clean_label,
    num_classes=num_class,
    K=10,
    N=1,
    THRESHOLD=0.6
)
# æ‰§è¡ŒåŠŸèƒ½3ï¼ˆé˜ˆå€¼THRESHOLD=0.6ï¼Œå³æŠ½æ ·æ­£ç¡®æ¯”ä¾‹â‰¥60%çš„ç°‡ä¸ºä»£è¡¨ç°‡ï¼‰
reassignment_results, new_labels_np, noise_labels_np = reassign_labels_by_centroid(
    features=features_tensor,
    noise_labels=noise_label,
    clean_labels=clean_label,
    K=10,
    N=1,
    THRESHOLD=0.6,
    top_ratio=0.9
)
# æ‰§è¡ŒåŠŸèƒ½4
# analyze_corrected_class_composition(
#     new_labels=np.array(new_labels_np),  # æ¥è‡ªåŠŸèƒ½3çš„ new_labels_np
#     clean_labels=clean_label.cpu().numpy(),
#     num_classes=num_class
# )

# æ‰§è¡ŒåŠŸèƒ½5
# è°ƒç”¨æ–°å¢åŠŸèƒ½5ï¼ˆéœ€ä» reassign_labels_by_centroid è¿”å› class_centroidsï¼‰
# æ³¨æ„ï¼šreassign_labels_by_centroid å½“å‰è¿”å›çš„æ˜¯ centroids çš„ list å½¢å¼ï¼Œéœ€è½¬å› numpy
# ä» reassignment_results ä¸­æ¢å¤ centroids ä¸º numpy æ•°ç»„



# æ‰§è¡ŒåŒºé—´å‡†ç¡®ç‡åˆ†æ
# class_centroids_np = {
#     k: np.array(v) for k, v in reassignment_results['class_centroids'].items()
# }
# interval_analysis_results = analyze_accuracy_by_confidence_intervals(
#     features=features_tensor,
#     noise_labels=noise_label,
#     clean_labels=clean_label,
#     new_labels=new_labels_np,
#     class_centroids=class_centroids_np,
#     num_classes=num_class
# )


# print("===== åŸå™ªå£°ç»„æˆ =====\n")


# analyze_corrected_class_composition(
#     new_labels=np.array(noise_labels_np),  # æ¥è‡ªåŠŸèƒ½3çš„ new_labels_np
#     clean_labels=clean_label.cpu().numpy(),
#     num_classes=num_class
# )



# -------------------------- 8. åŠŸèƒ½5ï¼šä¿å­˜ä¿®æ­£åçš„æ ‡ç­¾ä¸ºJSONæ–‡ä»¶ --------------------------
import json
import os

# ç¡®ä¿ç›®æ ‡ç›®å½•å­˜åœ¨
save_dir = f'./datasets/dino_mod/{dataset_name}'
os.makedirs(save_dir, exist_ok=True)

# å°† new_labels_np è½¬ä¸ºåˆ—è¡¨
new_labels_list = new_labels_np.tolist()

# ä¿å­˜è·¯å¾„
save_path = os.path.join(save_dir, f'dino_mod_labels_{noise_mode}_{noise_ratio}.json')

# å†™å…¥ JSON æ–‡ä»¶
with open(save_path, 'w') as f:
    json.dump(new_labels_list, f)

print(f"\nâœ… ä¿®æ­£åçš„æ ‡ç­¾å·²ä¿å­˜è‡³: {save_path}")